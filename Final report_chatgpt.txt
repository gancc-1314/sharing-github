Chatgpt-Q&A
Problem: Recommend users the top 10 similar movies based on genres.

Dataset: MovieLens Latest Datasets
Small: 100,000 ratings and 3,600 tag applications applied to 9,000 movies by 600 users. Last updated 9/2018. (https://files.grouplens.org/datasets/movielens/ml-latest-small.zip)

1) WorkFlow

	Here are some general procedures for building a movie recommendation system using machine learning:
Step 1. Define the problem: Determine the problem you want to solve with the recommendation system. For example, recommending products to customers or recommending movies to viewers.

Step 2. Data Collection and Preprocessing: Collect and preprocess data that you will use to train and test your recommendation system. This may involve merging multiple datasets, removing duplicates and incomplete data, and converting data into a format that can be used by machine learning algorithms.

Step 3. Feature Engineering: Create features that will be used to represent movies and users in your model. These features might include movie genres, actors, directors, release year, user age, and user gender.

Step 4. Model Selection/Choose an algorithm: Choose an appropriate machine learning algorithm that is appropriate for the data and problem. Common algorithms for recommendation systems include collaborative filtering, content-based filtering, and hybrid recommendation systems.

Step 5. Model Training: Train your machine learning model on the preprocessed data using the selected algorithm.

Step 6. Model Evaluation: Evaluate the performance of your recommendation system using a test set of data. Common evaluation metrics for recommendation systems include precision, recall, and F1 score.

Step 7. Hyperparameter Tuning: Tune the hyperparameters of your model to improve its performance. This may involve adjusting regularization strength, learning rate, or the number of latent factors.

Step 8. Deployment: Deploy your trained model in a production environment where it can make recommendations to users. This may involve building a web application or integrating the model into an existing application.

	Overall, this workflow involves collecting and preprocessing data, engineering features, selecting and training a machine learning model, evaluating its performance, tuning hyperparameters, and deploying the model in a production environment. y following these steps, you can build a recommendation system that provides accurate and personalized recommendations to users.


2) Preprocess Data
Here's a summary of the data preprocessing steps for this movie recommendation system:

1. Load the movie data from a CSV file.
2. Extract the genres data from the movie data.
3. Tokenize the genres data using NLTK's word_tokenize function.
4. Apply lemmatization to the tokenized genres using NLTK's WordNetLemmatizer.
5. Apply CountVectorizer from scikit-learn to the lemmatized genres to create a matrix of feature vectors for each movie.
_________________________________________________________________
Explanation in detail
3. Tokenization
	Tokenization is the process of breaking down a text into individual words, or tokens. In our codes, we used the 'word_tokenize' function from the 'nltk.tokenize' module to tokenize the genres data from movies. The 'word_tokenize' function takes a string as input and returns a list of tokens (i.e., individual words) extracted from the input string. Since the genres in our data are separated by '|', we replaced '|' with a space before tokenizing the genres data.

-------------------------------------------screenshot--------------------------------------------
from nltk.tokenize import word_tokenize

# tokenize genres
genre_tokens = [word_tokenize(genre.replace("|", " ")) for genre in genres]
-----------------------------------------------------------------------------------------------------

4. Lemmatization
	Lemmatization is the process of reducing a word to its base or dictionary form, so that different forms of a word (such as "run", "running", and "ran") are treated as the same word. By applying lemmatization to each word in the genre labels, the code can reduce these different variations to their base or dictionary form, which makes it easier to group similar genres together and analyze the data more accurately. In other words, the goal of lemmatization is to normalize words so that words with different inflections or forms are reduced to a common base form. By lemmatizing the words, we can reduce the vocabulary size and improve the accuracy of the machine learning models by reducing the sparsity of the matrix (i.e., reducing the number of zeros in the matrix). This is because lemmatizing words helps to group together different forms of the same word and treat them as the same token.
	In our code, we used the 'WordNetLemmatizer' class from the 'nltk.stem' module to lemmatize the tokens extracted from the genres data. The 'lemmatize' method of the 'WordNetLemmatizer' class takes a word as input and returns its lemma.

-------------------------------------------screenshot--------------------------------------------
from nltk.stem import WordNetLemmatizer

# apply lemmatizer
lemmatizer = WordNetLemmatizer()
genre_lemmas = [[lemmatizer.lemmatize(word) for word in tokens] for tokens in genre_tokens]
-----------------------------------------------------------------------------------------------------

5. Count vectorization
	Count vectorization is the process of converting a collection of text documents into a matrix of token counts. Each row in the resulting matrix represents a document, and each column represents a token (i.e., a word or a term). The values in the matrix represent the frequency of each token in each document. 
	In our code, we used the 'CountVectorizer' class from the 'sklearn.feature_extraction.text' module to perform count vectorization on the lemmatized genres data. The 'fit_transform' method of the 'CountVectorizer' class takes a list of strings (i.e., documents) as input and returns a matrix of token counts. In the resulting matrix, each row represents a movie and each column represents a unique word or n-gram in the vocabulary. The values in the matrix represent the frequency of each word or n-gram in each movie's genre label. The resulting matrix is a sparse matrix, which means that most of the values in the matrix are zero.
	Overall, the CountVectorizer class is used to tokenize the text data, which means converting each text document (in this case, each movie genre label) into a sequence of numerical values that represent the frequency of each word or n-gram (a sequence of adjacent words of length n) that can be used for machine learning in further process.

-------------------------------------------screenshot--------------------------------------------
from sklearn.feature_extraction.text import CountVectorizer

# apply CountVectorizer
cv = CountVectorizer(lowercase=True)
feature_matrix = cv.fit_transform([" ".join(lemmas) for lemmas in genre_lemmas]).toarray()
-----------------------------------------------------------------------------------------------------


After Preprocessing Data
6. Compute the pairwise cosine similarity matrix using scikit-learn's cosine_similarity function.
7. Use fuzzy matching from the fuzzywuzzy library to find the closest match to the user's input movie title.
8. Use the cosine similarity matrix to recommend the top 10 most similar movies to the user's input movie title.
_________________________________________________________________

3) What is an algorithm?
	In machine learning, an algorithm is a set of rules or instructions that a computer program follows to solve a particular problem. In other words, an algorithm is a mathematical formula or a series of steps that the machine learning model uses to learn patterns in the data and make predictions or decisions.
	In machine learning, algorithms are designed to automatically improve over time as they are exposed to more data. This process is called training, and it involves adjusting the parameters of the algorithm to minimize the difference between its predictions and the true values in the training data.
	Choosing the right algorithm for a particular problem requires careful consideration of the data, the problem domain, and the desired outcome. By selecting the right algorithm and fine-tuning its parameters, machine learning models can achieve high accuracy and make useful predictions or decisions.

6. Cosine Similarity
About cosine similarity:
	Cosine similarity is a measure of similarity between two non-zero vectors in a multi-dimensional space. The cosine similarity between two vectors is a measure of how similar they are in terms of the angles between them. It takes the dot product of the two vectors and divides it by the product of their magnitudes. The cosine similarity function takes two vectors as inputs and returns a value between -1 and 1, where a value of 1 means that the vectors are identical, a value of -1 means that they are completely dissimilar, and a value of 0 means that they are orthogonal (i.e., they have no shared direction).

Why choosing cosine similarity:
	Cosine similarity is an appropriate measure of similarity in this program because it is well-suited for comparing vectors in a high-dimensional space, such as the space of movie genres. It is commonly used in information retrieval and text mining applications, where it is used to calculate the similarity between documents based on the frequency of occurrence of words.

Applying cosine similarity in the program: 
	After obtaining the count vector representation of the genres in each movie, we can now compute the pairwise cosine similarity matrix to measure the similarity between movies based on their genres. In the context of this program, cosine similarity is used to compute the similarity between different movie genres based on their frequency of occurrence in the movies dataset.
	We use the 'cosine_similarity' function from scikit-learn's 'metrics.pairwise' module to compute the pairwise cosine similarity between all pairs of genre vectors in the movies dataset. The function takes an array 'feature_matrix' of shape (n_samples, n_features) as input, where n_samples is the number of movies in the dataset, and n_features is the number of unique genres in the dataset. The output of the 'cosine_similarity' function is a square matrix of shape (n_samples, n_samples) where each element (i,j) represents the cosine similarity between the genre vector for movie i and the genre vector for movie j.

---------------------------------------Screenshot------------------------------------------------
similarity_matrix = cosine_similarity(feature_matrix)
-----------------------------------------------------------------------------------------------------

	In this code, 'feature_matrix' is the count vector representation of the genres in each movie, which was computed using the 'CountVectorizer' from scikit-learn. The 'cosine_similarity' function takes this count vector matrix 'feature_matrix' as input and returns the pairwise cosine similarity matrix 'similarity_matrix'.
	Once we have the pairwise cosine similarity matrix, we can use it to find movies that are similar to a given movie. To do this, we will find the movies that have the highest cosine similarity scores with the given movie. We will then use the 'similarity_matrix' in the 'recommend_movies' function to find the top 10 most similar movies to a given movie, based on their genre similarity.

7. Closest Matching-fuzzy
	We prompt the user to enter a partial or full movie title and use fuzzy matching to find the closest match to the user's input. We divide the codes into three parts and analyze them in order.

Step 1: Import 'fuzz' module from the 'fuzzywuzzy' library
	We import the fuzz module from the fuzzywuzzy library to perform fuzzy matching. Fuzzy matching is a technique that finds the degree of similarity between two strings, which may not be an exact match. In our case, we use fuzzy matching to find the closest match to the user's input movie title in the list of movie titles in the dataset.

Step 2: Prompt the user to enter a partial or full (not necessary accurate) movie title

Step 3: Define the 'get_closest_match' function which takes the user input as an argument and returns the closest match from the list of movie titles in the dataset.
	The 'get_closest_match' function takes the user input title as an argument and returns the closest match from the titles list using fuzzy matching. It initializes 'highest_ratio' to 0 and 'close_match' to an empty string. It then iterates through the 'titles' list and calculates the fuzzy matching ratio between the user input title and each title in the list using the 'fuzz.ratio' function. If the ratio is higher than the current 'highest_ratio', it updates 'highest_ratio' and 'close_match'. Finally, it returns close_match which is the closest match to the user's input title.

----------------------------------------Screenshot-----------------------------------------------
from fuzzywuzzy import fuzz

# prompt the user to enter partial or full movie title
movie_title = input('Finding similar movies.\nPlease enter the movie title: ')

# Define function to find the closest match to the user's input using fuzzy matching
def get_closest_match(title):
    titles = movies_data['title']
    highest_ratio = 0
    close_match = ''
    for t in titles:
        ratio = fuzz.ratio(title.lower(), t.lower())
        if ratio > highest_ratio:
            highest_ratio = ratio
            close_match = t
    return close_match


# Find the closest match
closest_match = get_closest_match(movie_title)
print(f"Closest match found: {closest_match}")
-----------------------------------------------------------------------------------------------------

8. Producing recommended movies list 
	Once we have found the closest match to the user's input, we call the 'recommend_movies' function passing in the closest match, 'similarity_max', and 'movies_dt' as arguments. The 'recommend_movies' function finds the top 10 most similar movies to the closest match using the 'cosine_similarity' metric and prints them out for the user to see.

Knowing how the new-defined 'recommend_movies' function works in 7 steps:
Step 1: Find the index of the movie title in the movies_data DataFrame by checking which row has the closest match to the user's input movie title
-----------------------------------------Screenshot----------------------------------------------
    movie_index = movies_dt.index[movies_dt['title'] == close_match][0]
-----------------------------------------------------------------------------------------------------

Step 2: Get the similarity scores of the input movie with all other movies from the similarity matrix.
-----------------------------------------Screenshot----------------------------------------------
    similarity_scores = list(enumerate(similarity_max[movie_index]))
-----------------------------------------------------------------------------------------------------

Step 3: Sort the similarity scores in descending order.
-----------------------------------------Screenshot----------------------------------------------
    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)
-----------------------------------------------------------------------------------------------------

Step 4: Get the top 11 most similar movies (including the input movie) from the sorted similarity scores.
-----------------------------------------Screenshot----------------------------------------------
    top_11_movies = similarity_scores[:11]
-----------------------------------------------------------------------------------------------------

Step 5: Get the titles of the top 11 movies.
-----------------------------------------Screenshot----------------------------------------------
    top_11_titles = [movies_dt.iloc[movie[0]]['title'] for movie in top_11_movies]
-----------------------------------------------------------------------------------------------------

Step 6: Remove the closest match from the list of recommended movies and take only the top 10.
-----------------------------------------Screenshot----------------------------------------------
    top_10_movies = [title for title in top_11_titles if title != close_match][:10]
-----------------------------------------------------------------------------------------------------

Step 7: Print the recommended movies if there are any, or else print a message indicating that no similar movies were found.
-----------------------------------------Screenshot----------------------------------------------
    if len(top_10_movies) > 0:
        print(f"Top 10 recommended movies for {close_match}:")
        for i, movie in enumerate(top_10_movies, start=1):
            print(f"{i}. {movie}")
    else:
        print(f"No movies found similar to {close_match}.")
-----------------------------------------------------------------------------------------------------

Evaluation to be continue...

